{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1650a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\urvi\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\urvi\\anaconda3\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\urvi\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (2023.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torchvision) (1.19.3)\n",
      "Requirement already satisfied: requests in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from networkx->torch) (5.0.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\urvi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\urvi\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff968efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\urvi\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\urvi\\anaconda3\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\urvi\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torch) (2023.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torchvision) (1.19.3)\n",
      "Requirement already satisfied: requests in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from networkx->torch) (5.0.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\urvi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\urvi\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750002a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in c:\\users\\urvi\\anaconda3\\lib\\site-packages (4.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\urvi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\urvi\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade typing-extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd8548e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8852f628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\urvi\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement python3.10 (from versions: none)\n",
      "ERROR: No matching distribution found for python3.10\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3681e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430e10b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\urvi\\anaconda3\\lib\\site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from transformers) (1.19.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\urvi\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\urvi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\urvi\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35fc4701",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preliminaries\n",
    "\"\"\"\n",
    "We define a function to normalize a tweet to the format we used for TweetEval. Note that preprocessing is minimal (replacing user names by `@user` and links by `http`).\n",
    "\"\"\"\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12adfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel, TFAutoModel\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from collections import defaultdict\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdfe8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModel.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0477c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "  text = preprocess(text)\n",
    "  encoded_input = tokenizer(text, return_tensors='pt')\n",
    "  features = model(**encoded_input)\n",
    "  features = features[0].detach().cpu().numpy()\n",
    "  features_mean = np.mean(features[0], axis=0)\n",
    "  return features_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f2c835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to:  The book was awesome\n",
      "----------------------------------------\n",
      "1 The movie was great\n",
      "2 Just finished reading 'Embeddings in NLP'\n",
      "3 I just ordered fried chicken 🐣\n",
      "4 What time is the next game?\n"
     ]
    }
   ],
   "source": [
    "query = \"The book was awesome\"\n",
    "\n",
    "tweets = [\"I just ordered fried chicken 🐣\",\n",
    "          \"The movie was great\",\n",
    "          \"What time is the next game?\",\n",
    "          \"Just finished reading 'Embeddings in NLP'\"]\n",
    "\n",
    "d = defaultdict(int)\n",
    "for tweet in tweets:\n",
    "  sim = 1-cosine(get_embedding(query),get_embedding(tweet))\n",
    "  d[tweet] = sim\n",
    "\n",
    "print('Most similar to: ',query)\n",
    "print('----------------------------------------')\n",
    "for idx,x in enumerate(sorted(d.items(), key=lambda x:x[1], reverse=True)):\n",
    "  print(idx+1,x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c12354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base\"\n",
    "text = \"Good night 😊\"\n",
    "text = preprocess(text)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# Pytorch\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "model = AutoModel.from_pretrained(MODEL)\n",
    "features = model(**encoded_input)\n",
    "features = features[0].detach().cpu().numpy()\n",
    "features_mean = np.mean(features[0], axis=0)\n",
    "\n",
    "\n",
    "features_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52787797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "I am so <mask> 🤦🏻‍♂\n",
      "1)  tired 0.0814\n",
      "2)  confused 0.0713\n",
      "3)  hungry 0.0482\n",
      "4)  mad 0.0463\n",
      "5)  weak 0.0354\n",
      "------------------------------\n",
      "I am so <mask> 🥳\n",
      "1)  happy 0.3843\n",
      "2)  excited 0.2066\n",
      "3)  proud 0.1178\n",
      "4)  blessed 0.0427\n",
      "5)  grateful 0.0258\n",
      "------------------------------\n",
      "I am so <mask> 🍻\n",
      "1)  hungry 0.2078\n",
      "2)  happy 0.1753\n",
      "3)  excited 0.1415\n",
      "4)  full 0.0385\n",
      "5)  proud 0.036\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base\"\n",
    "fill_mask = pipeline(\"fill-mask\", model=MODEL, tokenizer=MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def print_candidates():\n",
    "    for i in range(5):\n",
    "        token = tokenizer.decode(candidates[i]['token'])\n",
    "        score = np.round(candidates[i]['score'], 4)\n",
    "        print(f\"{i+1}) {token} {score}\")\n",
    "\n",
    "texts = [\n",
    " \"I am so <mask> 🤦🏻‍♂\",\n",
    " \"I am so <mask> 🥳\",\n",
    "\"I am so <mask> 🍻\"\n",
    "]\n",
    "for text in texts:\n",
    "    t = preprocess(text)\n",
    "    print(f\"{'-'*30}\\n{t}\")\n",
    "    candidates = fill_mask(t)\n",
    "    print_candidates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5047fe11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) anger 0.5733\n",
      "2) sadness 0.398\n",
      "3) joy 0.0151\n",
      "4) optimism 0.0135\n"
     ]
    }
   ],
   "source": [
    "task='emotion'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "text = \"Why can't I find a good Indian restaurant\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a368d03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) joy 0.8186\n",
      "2) optimism 0.115\n",
      "3) anger 0.0425\n",
      "4) sadness 0.0239\n"
     ]
    }
   ],
   "source": [
    "text = \"you are pretty good\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "930d9edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues with task emoji: [Errno 2] No such file or directory: './datasets/emoji\\\\test_labels.txt'\n",
      "------------------------------\n",
      "aggregation of the individual task scores(F-1 Score):\n",
      "emoji: -1\n",
      "emotion: 0.7982724123055319\n",
      "hate: 0.5547114323640363\n",
      "irony: 0.6247755834829443\n",
      "offensive: 0.8155092112424851\n",
      "sentiment: 0.7285672376332831\n",
      "stance: 0.7243628109019552\n",
      "------------------------------\n",
      "TweetEval Score: -1\n"
     ]
    }
   ],
   "source": [
    "# usage: evaluaton_script.py [-h] [--tweeteval_path TWEETEVAL_PATH]\n",
    "#                            [--predictions_path PREDICTIONS_PATH] [--task TASK]\n",
    "\n",
    "# optional arguments:\n",
    "#   -h, --help: show this help message and exit\n",
    "#   --tweeteval_path: Path to TweetEval dataset\n",
    "#   --predictions_path: Path to predictions files\n",
    "#   --task: Use this to get single task detailed results\n",
    "#           (emoji|emotion|hate|irony|offensive|sentiment|stance)\n",
    "#\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import os\n",
    "import sys \n",
    "\n",
    "TASKS = [\n",
    "    'emoji', \n",
    "    'emotion',\n",
    "    'hate',\n",
    "    'irony',\n",
    "    'offensive',\n",
    "    'sentiment',\n",
    "    'stance']\n",
    "\n",
    "STANCE_TASKS = [\n",
    "    'abortion',\n",
    "    'atheism',\n",
    "    'climate',\n",
    "    'feminist',\n",
    "    'hillary']\n",
    "\n",
    "def load_gold_pred(args):\n",
    "    tweeteval_path = args.tweeteval_path\n",
    "    predictions_path = args.predictions_path\n",
    "    task = args.task\n",
    "\n",
    "    if 'stance' in task:\n",
    "        gold = []\n",
    "        pred = []\n",
    "        for stance_t in STANCE_TASKS:\n",
    "            gold_path = os.path.join(tweeteval_path,task,stance_t,'test_labels.txt')\n",
    "            pred_path = os.path.join(predictions_path,task,stance_t+'.txt')\n",
    "            gold.append(open(gold_path).read().split(\"\\n\")[:-1])\n",
    "            pred.append(open(pred_path).read().split(\"\\n\")[:-1])\n",
    "        # flatten lists of lists\n",
    "        gold = [p for each_target in gold for p in each_target]\n",
    "        pred = [p for each_target in pred for p in each_target]\n",
    "    else:\n",
    "        gold_path = os.path.join(tweeteval_path,task,'test_labels.txt')\n",
    "        pred_path = os.path.join(predictions_path,task+'.txt')\n",
    "        gold = open(gold_path).read().split(\"\\n\")[:-1]\n",
    "        pred = open(pred_path).read().split(\"\\n\")[:-1]\n",
    "        \n",
    "    return gold, pred\n",
    "\n",
    "def single_task_results(args):\n",
    "    task = args.task\n",
    "    tweeteval_result = -1\n",
    "    results = {}\n",
    "    \n",
    "    try:\n",
    "        gold, pred = load_gold_pred(args)\n",
    "        results = classification_report(gold, pred, output_dict=True)\n",
    "\n",
    "#         # Emoji (Macro f1)\n",
    "#         if 'emoji' in task:\n",
    "#             tweeteval_result = results['macro avg']['f1-score'] \n",
    "\n",
    "        # Emotion (Macro f1)\n",
    "        elif 'emotion' in task:\n",
    "            tweeteval_result = results['macro avg']['f1-score'] \n",
    "\n",
    "        # Hate (Macro f1)\n",
    "        elif 'hate' in task:\n",
    "            tweeteval_result = results['macro avg']['f1-score'] \n",
    "\n",
    "        # Irony (Irony class f1)\n",
    "        elif 'irony' in task:\n",
    "            tweeteval_result = results['1']['f1-score'] \n",
    "\n",
    "        # Offensive (Macro f1)\n",
    "        elif 'offensive' in task:\n",
    "            tweeteval_result = results['macro avg']['f1-score'] \n",
    "\n",
    "        # Sentiment (Macro Recall)\n",
    "        elif 'sentiment' in task:\n",
    "            tweeteval_result = results['macro avg']['recall']\n",
    "\n",
    "        # Stance (Macro F1 of 'favor' and 'against' classes)\n",
    "        elif 'stance' in task:\n",
    "            f1_against = results['1']['f1-score']\n",
    "            f1_favor = results['2']['f1-score']\n",
    "            tweeteval_result = (f1_against+f1_favor) / 2\n",
    "            \n",
    "    except Exception as ex:\n",
    "        print(f\"Issues with task {task}: {ex}\")\n",
    "        \n",
    "    return tweeteval_result, results\n",
    "\n",
    "def is_all_good(all_tweeteval_results):\n",
    "    return all([r != -1 for r in all_tweeteval_results.values()])\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='TweetEval evaluation script.')\n",
    "    \n",
    "    parser.add_argument('--tweeteval_path', default=\"./datasets/\", type=str, help='Path to TweetEval datasets')\n",
    "    parser.add_argument('--predictions_path', default=\"./predictions/\", type=str, help='Path to predictions files')\n",
    "    parser.add_argument('--task', default=\"\", type=str, help='Indicate this parameter to get single task detailed results')\n",
    "\n",
    "    # Modify this line to handle Jupyter Notebook environment\n",
    "    args = parser.parse_args([] if 'ipykernel' in sys.argv[0] else None)\n",
    "\n",
    "    if args.task == \"\":\n",
    "        all_tweeteval_results = {}\n",
    "        \n",
    "        # Results for each task\n",
    "        for t in TASKS:\n",
    "            args.task = t\n",
    "            all_tweeteval_results[t], _ = single_task_results(args)\n",
    "            \n",
    "        # Print results (score=-1 if some results are missing)\n",
    "        print(f\"{'-'*30}\")\n",
    "        if is_all_good(all_tweeteval_results):\n",
    "            tweeteval_final_score = sum(all_tweeteval_results.values())/len(all_tweeteval_results.values())\n",
    "        else:\n",
    "            tweeteval_final_score = -1\n",
    "        print(\"aggregation of the individual task scores(F-1 Score):\")\n",
    "        for t in TASKS:\n",
    "            # Each score\n",
    "            print(f\"{t}: {all_tweeteval_results[t]}\") \n",
    "        # Final score\n",
    "        print(f\"{'-'*30}\\nTweetEval Score: {tweeteval_final_score}\")\n",
    "        \n",
    "    else:\n",
    "        # Detailed results of one single task (--task parameter)\n",
    "        tweeteval_resut, results = single_task_results(args)\n",
    "        for k in results:\n",
    "            print(k, results[k])\n",
    "        print(f\"{'-'*30}\\nTweetEval Score ({args.task}): {tweeteval_resut}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122676f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
